{
  "name": "SenseGram",
  "tagline": "Transforming word embedding to word sense embeddings",
  "body": "# SenseGram\r\n\r\nThis repository contains implementation of a method that takes as an input a word embeddings, such as word2vec and splits different senses of the input words. For instance, the vector for the word \"table\" will be split into \"table (data)\" and \"table (furniture)\" as shown below. \r\n\r\nOur approach performs word sense induction and disambiguation based on sense embeddings. Sense inventory is induced from exhisting word embeddings via clustering of ego-networks of related words, such as one shown on the image below.\r\n\r\nDetailed description of the method is available in the original paper:\r\n\r\n- [**Original paper**](http://aclweb.org/anthology/W/W16/W16-1620.pdf)\r\n- [**Presentation**](https://raw.githubusercontent.com/tudarmstadt-lt/sensegram/master/docs/presentation.pdf)\r\n- [**Poster**](https://raw.githubusercontent.com/tudarmstadt-lt/sensegram/master/docs/poster.pdf)\r\n\r\n\r\nIf you use the method please cite the following paper:\r\n\r\n```\r\n@InProceedings{pelevina-EtAl:2016:RepL4NLP,\r\n  author    = {Pelevina, Maria  and  Arefiev, Nikolay  and  Biemann, Chris  and  Panchenko, Alexander},\r\n  title     = {Making Sense of Word Embeddings},\r\n  booktitle = {Proceedings of the 1st Workshop on Representation Learning for NLP},\r\n  month     = {August},\r\n  year      = {2016},\r\n  address   = {Berlin, Germany},\r\n  publisher = {Association for Computational Linguistics},\r\n  pages     = {174--183},\r\n  url       = {http://anthology.aclweb.org/W16-1620}\r\n}\r\n```\r\n\r\n# Learning of word sense embeddings\r\nThe picture below shows the overall architecture of word sense embedding learning from word senses. \r\n\r\n![ego](https://raw.githubusercontent.com/tudarmstadt-lt/sensegram/master/docs/pipeline.png)\r\n\r\n# Word sense induction\r\nWord senses are obtained by clustering of related words. This is an example of the word ego-network clustering. We use the Chinese Whispers algorithm.\r\n\r\n![ego](table3.png)\r\n\r\n# Word sense disambiguation\r\nOnce sense vectors are obtained, these can be used for disambiguation of words in context based on cosine similarity between context words and word prototypes.\r\n \r\n![ego](wsd.png)\r\n\r\n# Contact\r\nIf you have any question, please use the email indicated in the original paper or simply create a Github issue. \r\n\r\n",
  "note": "Don't delete this file! It's used internally to help with page regeneration."
}