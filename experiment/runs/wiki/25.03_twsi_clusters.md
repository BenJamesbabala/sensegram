**Expectations:** Should produce Precision = 1 and Recall = 1 on upper_bound evaluation

### Number of senses in TWSI clusters:
2333

### Hands-on analysis of twsi clusters

...

### Pooling of sense vectors (mean method) for wiki word vectors

**Expectations:** no parsing errors, hopefully no ommited small clusters

**Call:**

```
time ./pooling.py context-eval/data/Inventory-TWSI-2.csv 2333 model/wiki-sz300-w3-cb1-it3-min20.w2v model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.twsi.mean -inventory intermediate/twsi-clusters_inventory.csv --no_header
```

**Output:**

```
see intermediate/twsi_poolmean.log
```

**Observations:**
36 small clusters. For the sake of this experiment, don't filter out small clusters and repeat pooling

### Repeat pooling of sense vectors (any cluster size, mean method)

**Expectations:** no parsing errors, no ommited small clusters

**Call:**

```
time ./pooling.py context-eval/data/Inventory-TWSI-2.csv 2333 model/wiki-sz300-w3-cb1-it3-min20.w2v model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.twsi.mean -inventory intermediate/twsi-clusters_inventory.csv --no_header
```

**Output:**

```
Sense vectors: 2333, duplicates: 0, small: 0, clusters: 2333
Saving sense vectors...

real    2m23.212s
user    2m17.288s
sys     0m5.188s
```

**Observations:**
Expectations are met.

### Pooling of sense vectors (any cluster size, weighted method)

**Expectations:** nothing new. Identical inventory.

**Call:**

```
script intermediate/twsi_poolweighted.log

time ./pooling.py context-eval/data/Inventory-TWSI-2.csv 2333 model/wiki-sz300-w3-cb1-it3-min20.w2v model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.twsi.weighted --no_header -method weighted_mean
```

**Output:**

```
Loading original word model...
Vector size = 300
Initializing Word2Vec object for sense vectors...
Pooling cluster vectors (weighted_mean method)...
Progress: 0%  Column types: word       object
cid         int64
cluster    object
dtype: object                                                                                                                               100%
Sense vectors: 2333, duplicates: 0, small: 0, clusters: 2333
Saving sense vectors...

real    2m37.956s
user    2m30.204s
sys     0m5.804s
```

**Observations:**
Identical inventories, delete intermediate/twsi-clusters_inventory_weighted.csv. Assert if vectors differ for mean method and weighted.

### Upper bound evaluation
**Expectations:** 1 and 1 for precision and recall, full coverage.

**Call:**

```
time python twsi_upper_bound.py ~/experiment/intermediate/twsi-clusters_inventory.csv -predictions ~/experiment/context-eval/data/TWSI_dev.csv
```

**Output:**

```
Warning: wrong cluster word rel_terms
Warning: skipping word not present in TWSI vocabulary: cd
Warning: skipping word not present in TWSI vocabulary: cd
Warning: skipping word not present in TWSI vocabulary: tv
Warning: skipping word not present in TWSI vocabulary: tv
Mapping: data/Mapping_Inventory-TWSI-2.csv_twsi-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1010
user #senses: 2330.0
user average #senses per word: 2.31
 user unmapped senses: 0.30% (7 of 1010)
user unmapped words: []
twsi unmapped senses:
 twsi unmapped senses: 0.00% (0 of 2285)
Estimating upper bound performance:  /home/pelevina/experiment/context-eval/data/TWSI_dev.csv

Upper Bound Results:
Correct, retrieved, nr_sentences
6154    6165
Precision: 1.0  Recall: 0.998215733982  F1: 0.999107070379

real    0m23.970s
user    0m22.132s
sys     0m1.760s
```

**Observations:**
11 "mistakes" are made, how can it happen? Identify problematic rows:

connection 6306564
TV 10812559
TV 12517568
TV 12884703
TV 14612113
TV 14944277
TV 11121473
TV 1225385
TV 1238069
TV 13039441
TV 15537327

There are two test instances for connection+6306564 labeled in two different senses (1 and 4 twsi senses). Therefore, the second is skipped when ```correct``` is incremented. 

TV problem is caused by something being lowercased (target word of user inventory in mapping function).

### Prediction

**Expecation:**
none

**Call:**

```
time ./prediction.py context-eval/data/TWSI_dev.csv model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.twsi.mean model/wiki-sz300-w3-cb1-it3-min20.w2v.contexts eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.twsi.mean.csv

time ./prediction.py context-eval/data/TWSI_dev.csv model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.twsi.weighted model/wiki-sz300-w3-cb1-it3-min20.w2v.contexts eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.twsi.weighted.csv
```

**Output:**

```
â€¦


Loading models...
Loading test set...
6165 test instances
Start prediction over context-eval/data/TWSI_dev.csv
Progress: 100%
Saved predictions to eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.twsi.weighted.csv

real    3m1.938s
user    2m55.368s
sys     0m5.572s
```

### Evaluation
**Expecation:**
Lower value of precision signals faults of the wsd approach. What does low recall mean? In our case probably the same (cause recall is different from precision only if we decide not to predict something). Hopefully mean results will be different from results of weighted.

**Call:**

```
time python twsi_evaluation.py ~/experiment/intermediate/twsi-clusters_inventory.csv ~/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.twsi.mean.csv

time python twsi_evaluation.py ~/experiment/intermediate/twsi-clusters_inventory.csv ~/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.twsi.weighted.csv
```

**Output:**

```
Loading assigned TWSI senses...
Loading TWSI sense inventory...
Loading provided Sense Inventory /home/pelevina/experiment/intermediate/twsi-clusters_inventory.csv...
Warning: wrong cluster word rel_terms
Warning: skipping word not present in TWSI vocabulary: cd
Warning: skipping word not present in TWSI vocabulary: cd
Warning: skipping word not present in TWSI vocabulary: tv
Warning: skipping word not present in TWSI vocabulary: tv
Mapping: data/Mapping_Inventory-TWSI-2.csv_twsi-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1010
user #senses: 2330.0
user average #senses per word: 2.31
 user unmapped senses: 0.30% (7 of 1010)
user unmapped words: []
twsi unmapped senses:
 twsi unmapped senses: 0.00% (0 of 2285)
Evaluating Predicted Labels /home/pelevina/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.twsi.mean.csv...
Evaluated dataset: /home/pelevina/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.twsi.mean.csv-evaluated.csv

Evaluation Results:
Correct, retrieved, nr_sentences
2979    6154    6165
Precision: 0.484075398115       Recall: 0.483211678832  F1: 0.483643152853
Coverage:  0.998215733982

real    0m26.049s
user    0m23.820s
sys     0m1.872s


Loading assigned TWSI senses...
Loading TWSI sense inventory...
Loading provided Sense Inventory /home/pelevina/experiment/intermediate/twsi-clusters_inventory.csv...
Warning: wrong cluster word rel_terms
Warning: skipping word not present in TWSI vocabulary: cd
Warning: skipping word not present in TWSI vocabulary: cd
Warning: skipping word not present in TWSI vocabulary: tv
Warning: skipping word not present in TWSI vocabulary: tv
Mapping: data/Mapping_Inventory-TWSI-2.csv_twsi-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1010
user #senses: 2330.0
user average #senses per word: 2.31
 user unmapped senses: 0.30% (7 of 1010)
user unmapped words: []
twsi unmapped senses:
 twsi unmapped senses: 0.00% (0 of 2285)
Evaluating Predicted Labels /home/pelevina/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.twsi.weighted.csv...
Evaluated dataset: /home/pelevina/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.twsi.weighted.csv-evaluated.csv

Evaluation Results:
Correct, retrieved, nr_sentences
3211    6154    6165
Precision: 0.521774455639       Recall: 0.520843471208  F1: 0.521308547772
Coverage:  0.998215733982

real    0m26.973s
user    0m25.216s
sys     0m1.704s

```

**Observations** 
Quite poor results. It means more than half of senses is predicted incorrectly only because of bad vector pooling/prediction approach? Expect errors. Well, it does indeed make a lot of prediction mistakes. Partially it is already noticeable that sense vector may produce neighbours which are quite different from the cluser words they were based on. Plus the wsd on any particular context mey be not perfect.

weighted is indeed a little bit better!


