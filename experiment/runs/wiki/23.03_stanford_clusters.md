### Hands-on analysis of stanford (n50, n100, n200) clusters

â€¦

**Observations:**

* Small inventories! Why?
* At a first glanse clusters look good. For example, for the first time inventories (in 50 and 100) distinguish between academic=scientific and academic=scholar

### Number of clusters in Stanford inventories
**Goal:** number of clusters in all three Stanford inventories files

**Expectation:** n(50)>n(100)>n(200) because inventories differ in granularity and the number means ~cluster size

**Command:**

```
wc -l Inventory-WP-Stanford_a1_N200_n50.csv
wc -l Inventory-WP-Stanford_a1_N200_n100.csv
wc -l Inventory-WP-Stanford_a1_N200_n200.csv
```

**Output:**

```
5202 Inventory-WP-Stanford_a1_N200_n50.csv
3640 Inventory-WP-Stanford_a1_N200_n100.csv
2586 Inventory-WP-Stanford_a1_N200_n200.csv
```

**Observation:** Expectation confirmed. Files have no header so real count values are the same as output. 

### Parse errors in stanford clusters
none

### Pooling of sense vectors (mean method) for wiki word vectors
**Expectation:** 

Check parse errors. Cluster centre and cluster words are not lowercased

**Call:**

```
script intermediate/st50_poolmean.log
time ./pooling.py intermediate/Inventory-WP-Stanford_a1_N200_n50-count5202.csv 5202 model/wiki-sz300-w3-cb1-it3-min20.w2v model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.st50.mean -inventory intermediate/st50-clusters_inventory.csv --no_header

script intermediate/st100_poolmean.log
time ./pooling.py intermediate/Inventory-WP-Stanford_a1_N200_n100-count3640.csv 3640 model/wiki-sz300-w3-cb1-it3-min20.w2v model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.st100.mean -inventory intermediate/st100-clusters_inventory.csv --no_header

script intermediate/st200_poolmean.log
time ./pooling.py intermediate/Inventory-WP-Stanford_a1_N200_n200-count2586.csv 2586 model/wiki-sz300-w3-cb1-it3-min20.w2v model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.st200.mean -inventory intermediate/st200-clusters_inventory.csv --no_header
```

**Output:**

```
see intermediate/st50_poolmean.log
see intermediate/st100_poolmean.log
see intermediate/st200_poolmean.log
```

**Observations:**

For st50:

* from 5202 clusters to 5186 senses. 2 minutes.
* No errors during the split of a cluster
* only 16 small clusters deleted, some of them: 
	
	* 	"hit 1 [(u'pop', u'30'), (u'rock', u'23'), (u'disco', u'22')]"
	*	"colony 2 [(u'species', u'35'), (u'swarm', u'25'), (u'diversity', u'19'), (u'genus', u'18')]" (this sense gets lost)
	*	"grade 4 [(u'mm', u'26'), (u'cm', u'23'), (u'inch', u'21'), (u'millimetre', u'13')]" (this sense gets lost)
* Maybe lower cluster size threshold (now 5) for st50 inventory because it's so fine-graded?

For st100:

* from 3640 clusters to 3630 senses, 2 minutes
* only 10 clusters deleted, among them 'colony 2'
* No errors during split of a cluster

For st200:

* from 2586 clusters to 2580 senses
* No errors during split of a cluster
* 6 deleted clusters, none of them look important





### Upper_bound evaluation
**Expectation:** cannot be as good as ukwac/wiki because there is not enough vocabulary. Even though the granulation of clusters looked good. 100 is most balanced in my opinion: upper-bound of 50 might be better, but balanced st100 might be better during prediction.

**Call:**

```
time python twsi_upper_bound.py ~/experiment/intermediate/st50-clusters_inventory.csv -predictions ~/experiment/context-eval/data/TWSI_dev.csv

time python twsi_upper_bound.py ~/experiment/intermediate/st100-clusters_inventory.csv -predictions ~/experiment/context-eval/data/TWSI_dev.csv

time python twsi_upper_bound.py ~/experiment/intermediate/st200-clusters_inventory.csv -predictions ~/experiment/context-eval/data/TWSI_dev.csv
```

**Output:**

```
Mapping: data/Mapping_Inventory-TWSI-2.csv_st50-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1009
user #senses: 5175.0
user average #senses per word: 5.13
 user unmapped senses: 35.73% (1849 of 1009)
user unmapped words: [u'disambiguation', u'former', u'instrumental']
twsi unmapped senses:
 twsi unmapped senses: 28.36% (648 of 2285)
Estimating upper bound performance:  /home/pelevina/experiment/context-eval/data/TWSI_dev.csv

Upper Bound Results:
Correct, retrieved, nr_sentences
4465    6165
Precision: 1.0  Recall: 0.724249797242  F1: 0.840075258702

real    0m27.355s
user    0m25.588s
sys     0m1.652s


Mapping: data/Mapping_Inventory-TWSI-2.csv_st100-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1009
user #senses: 3623.0
user average #senses per word: 3.59
 user unmapped senses: 29.23% (1059 of 1009)
user unmapped words: [u'disambiguation', u'former', u'instrumental']
twsi unmapped senses:
 twsi unmapped senses: 33.17% (758 of 2285)
Estimating upper bound performance:  /home/pelevina/experiment/context-eval/data/TWSI_dev.csv

Upper Bound Results:
Correct, retrieved, nr_sentences
4135    6165
Precision: 1.0  Recall: 0.670721816707  F1: 0.802912621359

real    0m25.727s
user    0m23.160s
sys     0m1.636s


Mapping: data/Mapping_Inventory-TWSI-2.csv_st200-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1010
user #senses: 2575.0
user average #senses per word: 2.55
 user unmapped senses: 22.14% (570 of 1010)
user unmapped words: [u'disambiguation', u'former', u'instrumental']
twsi unmapped senses:
 twsi unmapped senses: 38.38% (877 of 2285)
Estimating upper bound performance:  /home/pelevina/experiment/context-eval/data/TWSI_dev.csv

Upper Bound Results:
Correct, retrieved, nr_sentences
3685    6165
Precision: 1.0  Recall: 0.597729115977  F1: 0.748223350254

real    0m23.058s
user    0m20.812s
sys     0m1.580s
```

**Observations:**

For st50:

* No, these vectors are not worse.
* number of unmapped TWSI senses decreased from 1003 to 648.
* average senses per word is 5.13 compared to 1.89
* *However, an idea: upper_bound evaluation of inventory may have a bias towards very fine-graned inventories that are not necessarily good (Imagine 10 user senses vs 3 twsi sense and a mapping like 1-7 user -> 1twsi, 8-9 user -> 2 twsi, 10user -> 3twsi. Yes, all twsi senses are covered but 7 senses for basically the same meaning isn't good.)*

For st100:

### Prediction on TWSI devset (mean)
**Expectations:** none yet

**Call:**

```
time ./prediction.py context-eval/data/TWSI_dev.csv model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.st50.mean model/wiki-sz300-w3-cb1-it3-min20.w2v.contexts eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st50.mean.csv

time ./prediction.py context-eval/data/TWSI_dev.csv model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.st100.mean model/wiki-sz300-w3-cb1-it3-min20.w2v.contexts eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st100.mean.csv

time ./prediction.py context-eval/data/TWSI_dev.csv model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.st200.mean model/wiki-sz300-w3-cb1-it3-min20.w2v.contexts eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st200.mean.csv
```

**Output:**

```
Loading models...
Loading test set...
6165 test instances
Start prediction over context-eval/data/TWSI_dev.csv
Progress: 100%
Saved predictions to eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st50.mean.csv

real    3m6.680s
user    2m54.456s
sys     0m7.580s

Loading models...
Loading test set...
6165 test instances
Start prediction over context-eval/data/TWSI_dev.csv
Progress: 100%
Saved predictions to eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st100.mean.csv

real    2m39.459s
user    2m33.008s
sys     0m5.440s

Loading models...
Loading test set...
6165 test instances
Start prediction over context-eval/data/TWSI_dev.csv
Progress: 100%
Saved predictions to eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st200.mean.csv

real    2m16.257s
user    2m10.272s
sys     0m5.256s
```

**Observation:** 

* Very fast! Understand why.

	* Because prediction.py calls *most_similar* on sense vectors and execution time of this call depends on the number of sense vectors (small for stanford cluster, large for wikijb/ukwac). Most similar senses are used to fill the *predicted_related_term* column of the prediction dataset.
	
* Check predictions before evaluation.

### Evaluation

**Call:**

```
time python twsi_evaluation.py ../intermediate/st50-clusters_inventory.csv ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st50.mean.csv

time python twsi_evaluation.py ../intermediate/st100-clusters_inventory.csv ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st100.mean.csv

time python twsi_evaluation.py ../intermediate/st200-clusters_inventory.csv ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st200.mean.csv
```

**Output:**

```
Evaluated dataset: ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st50.mean.csv-evaluated.csv

Evaluation Results:
Correct, retrieved, nr_sentences
1694    6154    6165
Precision: 0.275268118297       Recall: 0.274776966748  F1: 0.275022323241
Coverage:  0.998215733982

real    0m23.870s
user    0m22.036s
sys     0m1.556s

Mapping: data/Mapping_Inventory-TWSI-2.csv_st100-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1009
user #senses: 3623.0
user average #senses per word: 3.59
 user unmapped senses: 29.23% (1059 of 1009)
user unmapped words: [u'disambiguation', u'former', u'instrumental']
twsi unmapped senses:
 twsi unmapped senses: 33.17% (758 of 2285)
Evaluating Predicted Labels ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st100.mean.csv...
Evaluated dataset: ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st100.mean.csv-evaluated.csv

Evaluation Results:
Correct, retrieved, nr_sentences
1877    6154    6165
Precision: 0.305004874878       Recall: 0.304460665045  F1: 0.304732526991
Coverage:  0.998215733982

real    0m23.129s
user    0m21.552s
sys     0m1.524s


Mapping: data/Mapping_Inventory-TWSI-2.csv_st200-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1010
user #senses: 2575.0
user average #senses per word: 2.55
 user unmapped senses: 22.14% (570 of 1010)
user unmapped words: [u'disambiguation', u'former', u'instrumental']
twsi unmapped senses:
 twsi unmapped senses: 38.38% (877 of 2285)
Evaluating Predicted Labels ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st200.mean.csv...
Evaluated dataset: ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.st200.mean.csv-evaluated.csv

Evaluation Results:
Correct, retrieved, nr_sentences
2079    6154    6165
Precision: 0.337829054274       Recall: 0.337226277372  F1: 0.337527396704
Coverage:  0.998215733982

real    0m22.321s
user    0m20.800s
sys     0m1.484s
```

**Observations:** Check and double check prediction. Only then report values. Indeed, fine-grained -> low precision.
