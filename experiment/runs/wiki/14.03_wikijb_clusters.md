### Number of clusters in JoBim wiki file
**Goal:** number of clusters in wiki JoBim clusters file 

**Command:**

```
iparker1$ wc -l dt-wiki-deps-jst-wpf1k-fpw1k-thr.csv-cw-e0-N200-n200-minsize15.csv
```

**Output:**

```
  930409 dt-wiki-deps-jst-wpf1k-fpw1k-thr.csv-cw-e0-N200-n200-minsize15.csv
```

**Observation:** 930409 - 1 clusters because first line is a header.

### Hands-on analysis of JoBim wiki
**Goal:**

* Inspect cluster for words ruby, python, Ruby, Python, tree (TWSI plant/structure), accident (TWSI tragedy/unexpected), pilot (TWSI trial/aviator)

**Expectation:**
Clusters not worse than ukwac clusters.

**Observations:**

* ruby: gem/color/smth strange (*with:0.018,out:0.018,like:0.018,on:0.017*)
* Ruby: name/language
* python: snake
* Python: Snake(capitalized animals)/language
* tree: plant (only one sense!)
* accident: disaster (only one sense!)
* pilot: fly(verbs)/aviator

For "tree" and "accident" wiki clusters is the same as ukwac. But for pilot it is worse. Ukwac has senses "trial", "aviator" and some mixed "aircraft/plane".


### Parse errors in wiki JoBim clusters 
**Goal:** Check for csv parsing errors of the clusters file in pooling.py. Decide whether to throw away wrong clusters completely or only words in those clusters

**Expectation:** Some words may contain commas or colon, which are used in DT format as separators. This will cause problems.

**Call:** See notebook intermediate/wiki-clusters_parse_errors

**Observation:**

* Definitely don't skip whole clusters, many problems are simply like this: 
 
	acyl-coa:0.003,dihydrofolate:0.003,a,c-diamide:0.003
	
* Mostly appear in cluster of words that are garbage (me., 10-4, st.), but sometimes not (heraldry, one-half, became)

### Pooling of sense vectors from wiki JoBim clusters (mean method) for wiki word vectors
**Expectation:** 

* Due to parse errors and some words not appearing in the word vector model, some clusters may loose items and get smaller than 5. These will be left out. Check that they do not contain important words and senses. 
* Cluster centre and cluster words are not lowercased

**Call:**

```
script wikijb_poolmean.log

time ./pooling.py intermediate/wiki-clusters-dep-cw-e0-N200-n200-minsize15-count930408.csv 930408 model/wiki-sz300-w3-cb1-it3-min20.w2v model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.mean -inventory intermediate/wiki-clusters_inventory_mean.csv
```

**Output:** see intermediate/wikijb_poolmean.log

**Observations:**

* all deleted clusters are unimportant garbage.
* only 0.5% deleted (it makes sense, because original clusters had at least 15 items and we prune them by minsize 5)
* results in 925104 senses
* letter case is correct
* 11 minutes

### 30.03 Pooling of sense vectors from wiki JoBim clusters (weighted method) for wiki word vectors
**Expectation:** 

No statistical changes if compared to mean pooling: same number of senses, of small clusters, identical inventory

**Call:**

```
script wikijb_poolweighted.log

time ./pooling.py intermediate/wiki-clusters-dep-cw-e0-N200-n200-minsize15-count930408.csv 930408 model/wiki-sz300-w3-cb1-it3-min20.w2v model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.wiki.weighted -method weighted_mean
```
**Output:** see intermediate/wikijb_poolweighted.log

```
Sense vectors: 926874, duplicates: 0, small: 3534, clusters: 930408
Saving sense vectors...

real    13m16.474s
user    13m0.732s
sys     0m11.216s
```

**Observations:**

* Actually different number of sense vectors, because parsing method has been slightly changed. The difference is neglegtable compared to total number of clusters. Update inventory

**Note:** leave last inventory named ```wiki-clusters_inventory.csv``

### 17.03: Upper-bound of wiki-clusters_inventory on devset
**Expectation:** none at the moment.
Can be compared with upper_bound of ukwac inventory on devset. It will tell us which external clusters (wiki or ukwac) is better.

**Call:**

```
time python twsi_upper_bound.py ~/experiment/intermediate/wiki-clusters_inventory.csv
```
**Output:** Parse error in inventory. 

```
pandas.parser.CParserError: Error tokenizing data. C error: EOF inside string starting at line 726743
Change TWSI dataset.
```

### 21.03: Try upper bound on original wiki clusters
**Goal:** To see if previous error has been caused by my pooling method that changes slightly the inventory (reassigns sense numbers and skips cluster words not used for pooling).

**Call:**

```
time python twsi_upper_bound.py ~/experiment/intermediate/wiki-clusters-dep-cw-e0-N200-n200-minsize15-count930408.csv
```
**Output:** no error. 

**Result:** Continued search for parse errors [here](/home/pelevina/experiment/intermediate/Analysis_wikijb_clusters.ipynb) on frink. Errors found, problem detected (don't use doublequotes as an escape characted in read_csv), TWSI_evaluation script adapted. Now repeat upper_bound on *my* inventory, maybe pooling script was not the one to blame. (Spoiler: it wasn't!)

### 21.03: Repeat Upper-bound of wiki-clusters_inventory on devset
**Goal:** Calculate upper bound of wikijb clusters on TWSI devset.
**Adjustment:** upeer_bound.py script takes prediction dataset as a parameter (for now it's hardcoded to the full TWSI)

**Call:**

```
time python twsi_upper_bound.py ~/experiment/intermediate/wiki-clusters_inventory.csv -predictions ~/experiment/context-eval/data/TWSI_dev.csv
```
**Output:**

```
Mapping: data/Mapping_Inventory-TWSI-2.csv_wiki-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1010
user #senses: 1659.0
user average #senses per word: 1.64
user unmapped senses: 9.58% (159 of 1010)
user unmapped words: [u'disambiguation', u'form']
twsi unmapped senses:
twsi unmapped senses: 46.87% (1071 of 2285)
Estimating upper bound performance:  /home/pelevina/experiment/context-eval/data/TWSI_dev.csv

Upper Bound Results:
Correct, retrieved, nr_sentences
3009 	6165
Precision: 1.0 	Recall: 0.488077858881 	F1: 0.655984303466
```


### 17.03: Prediction on devset (mean)
**Expectation:** none

**Call:**

```
time ./prediction.py context-eval/data/TWSI_dev.csv model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.mean model/wiki-sz300-w3-cb1-it3-min20.w2v.contexts eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.mean.csv
```
**Output:**

```
6165 test instances
Start prediction over context-eval/data/TWSI_dev.csv
Progress: 100%
Saved predictions to eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.mean.csv

real    43m39.635s
user    43m20.672s
sys     0m8.376s
```

**Observation:** Some neihgbours (related_terms) of the sense  ```academic#0``` start with double quotes, which actually shouldn't happen (```""scientific```). The column 'related_terms' is wraped into doublequotes.

**Result:** Add parameter ```quoting=csv.QUOTE_NONE``` to ```to_csv``` function call in ```prediction.py```. Wrapping and additional doublequotes where result of '"' being a default escape character.

### 21.03: Repeat prediction on devset (mean)
**Expectation:** none

**Call:**

```
time ./prediction.py context-eval/data/TWSI_dev.csv model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.mean model/wiki-sz300-w3-cb1-it3-min20.w2v.contexts eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.mean.csv
```
**Output:**

```
Loading models...
Loading test set...
6165 test instances
Start prediction over context-eval/data/TWSI_dev.csv
Progress: 100%
Saved predictions to eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.mean.csv

real    41m23.372s
user    41m8.992s
sys     0m8.056s
```

### 22.03 Evaluation devset (mean)
**Goal:** Evaluate predictions, compare to upper_bound.

**Call:**

```
time python twsi_evaluation.py ../intermediate/wiki-clusters_inventory.csv ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.mean.csv
```

**Output:**

```
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1010
user #senses: 1659.0
user average #senses per word: 1.64
 user unmapped senses: 9.58% (159 of 1010)
user unmapped words: [u'disambiguation', u'form']
twsi unmapped senses:
 twsi unmapped senses: 46.87% (1071 of 2285)
Evaluating Predicted Labels ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.mean.csv...
Evaluated dataset: ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.mean.csv-evaluated.csv

Evaluation Results:
Correct, retrieved, nr_sentences
2361 	6164 	6165
Precision: 0.383030499676 	Recall: 0.38296836983 	F1: 0.382999432233
Coverage:  0.999837793998
```
**Observations:** Investigate "-evaluated" file, find out mistakes of any other format than "-1 0" (mistakes caused by unmapped sense). In addition to this, assume that upperbound_recall - evaluation_recall tells us how many instances could have been predicted correctly if the wsd method were better.

### 31.03 Evaluation devset (weighted)
**Goal:** Evaluate predictions with different pooling method, compare with mean experiment. 
**Call:**

```
time python twsi_evaluation.py ../intermediate/wiki-clusters_inventory.csv ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.weighted.csv
```

**Output:**

```
Mapping: data/Mapping_Inventory-TWSI-2.csv_wiki-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1010
user #senses: 1659.0
user average #senses per word: 1.64
 user unmapped senses: 9.58% (159 of 1010)
user unmapped words: [u'disambiguation', u'form']
twsi unmapped senses:
 twsi unmapped senses: 46.87% (1071 of 2285)
Evaluating Predicted Labels ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.weighted.csv...
Evaluated dataset: ../eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.weighted.csv-evaluated.csv

Evaluation Results:
Correct, retrieved, nr_sentences
2361 	6164 	6165
Precision: 0.383030499676 	Recall: 0.38296836983 	F1: 0.382999432233
Coverage:  0.999837793998

real	3m46.156s
user	2m38.352s
sys	0m8.952s
```

**Observation:**
No difference at all from vector pooling method.

### 30.03: Evaluate weighted sense vectors, standart sep wsd method

**Expectation:** better than mean vectors. If too much better -> repeat mean evaluation with this slightly new inventory

**Call:**

```
time ./prediction.py context-eval/data/TWSI_dev.csv model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.wiki.weighted model/wiki-sz300-w3-cb1-it3-min20.w2v.contexts eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.wiki.weighted.sep.csv && cd context-eval && time python twsi_evaluation.py ~/experiment/intermediate/wiki-clusters_inventory.csv ~/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.wiki.weighted.sep.csv
```

**Output:**

```
Mapping: data/Mapping_Inventory-TWSI-2.csv_wiki-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1010
user #senses: 1659.0
user average #senses per word: 1.64
 user unmapped senses: 9.58% (159 of 1010)
user unmapped words: [u'disambiguation', u'form']
twsi unmapped senses:
 twsi unmapped senses: 46.87% (1071 of 2285)
Evaluating Predicted Labels /home/pelevina/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.wiki.weighted.sep.csv...
Evaluated dataset: /home/pelevina/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.wiki.weighted.sep.csv-evaluated.csv

Evaluation Results:
Correct, retrieved, nr_sentences
2386    6164    6165
Precision: 0.387086307592       Recall: 0.38702351987   F1: 0.387054911185
Coverage:  0.999837793998

real    2m54.849s
user    2m39.788s
sys     0m8.876s
```

**Observations:** indeed slightly better than mean pooling of sense vectors

### 30.03: Try second disambiguation approach (avg)

**Expectation:** small improvement over previous experiment

**Call:**

```
time ./prediction.py context-eval/data/TWSI_dev.csv model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.wiki.weighted model/wiki-sz300-w3-cb1-it3-min20.w2v.contexts eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.wiki.weighted.avg.csv -wsd_method avg && cd context-eval && time python twsi_evaluation.py ~/experiment/intermediate/wiki-clusters_inventory.csv ~/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.wiki.weighted.avg.csv
```
**Output:**

```
Mapping: data/Mapping_Inventory-TWSI-2.csv_wiki-clusters_inventory.csv
twsi #words: 1010
twsi #senses: 2285.0
twsi average #senses per word: 2.26
user #words: 1010
user #senses: 1659.0
user average #senses per word: 1.64
 user unmapped senses: 9.58% (159 of 1010)
user unmapped words: [u'disambiguation', u'form']
twsi unmapped senses:
 twsi unmapped senses: 46.87% (1071 of 2285)
Evaluating Predicted Labels /home/pelevina/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.wiki.weighted.avg.csv...
Evaluated dataset: /home/pelevina/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.wiki.weighted.avg.csv-evaluated.csv

Evaluation Results:
Correct, retrieved, nr_sentences
2386    6164    6165
Precision: 0.387086307592       Recall: 0.38702351987   F1: 0.387054911185
Coverage:  0.999837793998

real    2m56.786s
user    2m41.220s
sys     0m9.272s
```

**Observation:**
No difference to sep wsd approach

### 30:03 Repeat mean experiment with standart sep wsd approach

**Call:**

```
time ./prediction.py context-eval/data/TWSI_dev.csv model/wiki-sz300-w3-cb1-it3-min20.w2v.senses.wiki.mean model/wiki-sz300-w3-cb1-it3-min20.w2v.contexts eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.wiki.mean.sep.csv && cd context-eval && time python twsi_evaluation.py ~/experiment/intermediate/wiki-clusters_inventory.csv ~/experiment/eval/TWSI_dev_wiki-sz300-w3-cb1-it3-min20.wiki.mean.sep.csv
```
**Observation:** identical
